# Compose

## ğŸ“‹ Prerrequisitos
- **Docker** y **Docker Compose** instalados.
- **Node.js** (v14+) para los mÃ³dulos JavaScript.
- Permisos de superusuario si ejecutas Docker con `sudo`.

---

## ğŸš€ Levantar los servicios con Docker Compose

1. **Detener contenedores activos**  
   ```bash
   sudo docker compose down
   ```
2. **Construir y arrancar**
```bash
sudo docker compose build --no-cache
sudo docker compose up
```
Esto iniciarÃ¡:

- Elasticsearch en https://localhost:9200 (usuario: elastic, contraseÃ±a: changeme)

- Scraper:
1. Indexa traffic_data.csv en batches de 1 000 registros.
2. Comienza a scrapear datos de Waze.

- API de consultas en http://localhost:8080

## ğŸ”€ Generador aleatorio de trÃ¡fico

```bash
cd generator
npm install
node randomGenerator.js <nÃºmero de queries> <distribucion> <pâ‚: probabilidad de comuna> <pâ‚‚: probabilidad de alerta> <pâ‚ƒ: probabilidad de tipo>
```
Es recomendable esperar a que el scraper haya comenzado a procesar los datos de Waze antes de ejecutar el comando del generador de trÃ¡fico.

-Ejemplo:
```bash
node randomGenerator.js 1000 pareto 1 1 0
```
La rama main estÃ¡ preparada para emplear LRU (allkeys-lru), mientras que la rama random_metricas utiliza la polÃ­tica aleatoria (allkeys-random). 

## ğŸ“¡ Scraper
**Instalar dependencias**
```bash
cd scrapper
npm install
```
Arrancar el servicio
```bash
node index.js
```
## ğŸ—„ï¸ Servidor de Base de Datos (Elastic)

**Instalar dependencias**
```bash
cd Elastic
npm install
```
Arrancar el servidor
```bash
node server.js
```
## âš™ï¸ Pruebas con `curl`

**Obtener todas las consultas:**
```bash
curl 'http://localhost:8080/consultas'
```
**Obtener todas las consultas:**
```bash
curl 'http://localhost:8080/consultas?alerttype=alert'
```

